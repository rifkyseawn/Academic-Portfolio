{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCittGg_TLs7"
      },
      "source": [
        "# Qudud: Quit Smoking Chatbot Assistant\n",
        "**Research Portfolio, Rifky Setiawan, Universitas Gadjah Mada (UGM)**\n",
        "\n",
        "\n",
        "This notebook presents a compact, modular chatbot for quit-smoking support. It combines a lightweight retrieval component, an intent classifier, a transparent dialogue policy, and a small retrieval-augmented response step. The design focuses on clarity, safety, and reproducibility for academic review.\n"
      ],
      "id": "nCittGg_TLs7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4JhN4hUTLs8"
      },
      "source": [
        "## Abstract\n",
        "\n",
        "This portfolio notebook demonstrates a small end-to-end quit-smoking assistant named **Qudud**. The system integrates four parts: (1) content acquisition for a basic corpus, (2) bag-of-words retrieval to ground responses, (3) a compact intent classifier with TF‑IDF features and logistic regression from scikit-learn, and (4) a rule-based dialogue policy with a safety layer and a minimal retrieval-augmented step. The implementation is intentionally simple to keep the behavior transparent while remaining extensible for future research.\n"
      ],
      "id": "i4JhN4hUTLs8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai8vSS2nTLs9"
      },
      "source": [
        "## 1. Problem Statement and Motivation\n",
        "\n",
        "Quit-smoking coaching needs practical guidance that is available on demand. Many users benefit from short suggestions during cravings, relapse handling that is non-judgmental, and structured planning advice. This notebook provides a clean reference implementation of a transparent assistant that can be extended with larger models later while keeping a clear baseline for evaluation and ablation studies.\n"
      ],
      "id": "ai8vSS2nTLs9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vgUdF1oTLs9"
      },
      "source": [
        "## 2. Pipeline Overview\n",
        "\n",
        "- **Content Acquisition:** scrape a few public health pages to build a small text corpus; fail gracefully if network access is not available.  \n",
        "- **Text Preparation:** sentence tokenization and basic cleaning.  \n",
        "- **Retrieval Module:** bag-of-words similarity with cosine distance to echo relevant sentences.  \n",
        "- **Intent Classification:** TF‑IDF features and a logistic regression classifier for a small set of intents.  \n",
        "- **Dialogue Policy:** rule-based policy that uses intents to select supportive messages with stage tracking.  \n",
        "- **Safety Filter:** keyword-based guard that replaces unsafe outputs with a fallback message.  \n",
        "- **RAG Step:** append one short retrieved tip that matches the user query to improve specificity.\n"
      ],
      "id": "-vgUdF1oTLs9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V2XOWxJTLs-"
      },
      "source": [
        "## 3. Environment Setup and Dependencies\n",
        "\n",
        "The installation cell below installs the required libraries. Internet access may be needed for newspaper3k scraping and for downloading NLTK tokenizers.\n"
      ],
      "id": "0V2XOWxJTLs-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypLF48G6TLs_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Environment Setup and Dependencies\n",
        "# Note: If running on restricted environments, scraping may fail. The code will fall back to a small built-in corpus.\n",
        "\n",
        "%pip install -q nltk newspaper3k lxml_html_clean\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import random\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "from newspaper import Article\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Ensure sentence tokenizer data; handle newer NLTK expecting 'punkt_tab'\n",
        "try:\n",
        "    nltk.data.find(\"tokenizers/punkt\")\n",
        "except LookupError:\n",
        "    nltk.download(\"punkt\", quiet=True)\n",
        "\n",
        "try:\n",
        "    nltk.data.find(\"tokenizers/punkt_tab\")\n",
        "except LookupError:\n",
        "    try:\n",
        "        nltk.download(\"punkt_tab\", quiet=True)\n",
        "    except Exception:\n",
        "        pass  # ignore if unavailable; downstream code uses a safe fallback\n",
        "\n",
        "# Reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ],
      "id": "ypLF48G6TLs_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgIQjMdNTLs_"
      },
      "source": [
        "## 4. Setup and Imports\n",
        "\n",
        "This cell gathers all imports in one place and performs lightweight initialization. The tokenizer is downloaded once.\n"
      ],
      "id": "WgIQjMdNTLs_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfKjdrLdTLs_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Minimal Safety Layer\n",
        "\n",
        "# Minimal keyword-based safety\n",
        "BLOCKLIST = {\"self-harm\", \"suicide\", \"kill myself\", \"harm others\"}\n",
        "SAFE_FALLBACK = \"I want to keep you safe. If you feel at risk, please contact local emergency services or a trusted person.\"\n",
        "\n",
        "def is_unsafe(text: str) -> bool:\n",
        "    t = (text or \"\").lower()\n",
        "    return any(k in t for k in BLOCKLIST)\n",
        "\n",
        "def apply_safety(input_text: str, output_text: str) -> str:\n",
        "    if is_unsafe(input_text) or is_unsafe(output_text):\n",
        "        return SAFE_FALLBACK\n",
        "    return output_text"
      ],
      "id": "NfKjdrLdTLs_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx12SqOMTLs_"
      },
      "source": [
        "## 5. Safety Utilities\n",
        "\n",
        "A minimal safety layer checks simple keyword patterns and replaces unsafe outputs with a supportive fallback. This is not a substitute for professional help. It serves as a visible baseline that can be expanded with more robust detection.\n"
      ],
      "id": "zx12SqOMTLs_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUZDz1NiTLs_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Content Acquisition\n",
        "\n",
        "def scrape_articles(urls: List[str]) -> str:\n",
        "    \"\"\"Fetch and concatenate article text from a list of URLs.\n",
        "    Returns an empty string if all fetches fail.\n",
        "    \"\"\"\n",
        "    corpus_parts = []\n",
        "    for url in urls:\n",
        "        try:\n",
        "            art = Article(url)\n",
        "            art.download()\n",
        "            art.parse()\n",
        "            # art.nlp() is optional; not strictly required for .text\n",
        "            corpus_parts.append(art.text.strip())\n",
        "        except Exception as e:\n",
        "            # Keep going if one source fails\n",
        "            continue\n",
        "    return \"\\n\\n\".join([c for c in corpus_parts if c])"
      ],
      "id": "AUZDz1NiTLs_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bHSrFlUTLs_"
      },
      "source": [
        "## 6. Content Acquisition (Scraper)\n",
        "\n",
        "This function scrapes a few public health resources. If a page fails to load, the function continues with the remaining sources. If all pages fail, the code falls back to a small built-in snippet list.\n"
      ],
      "id": "8bHSrFlUTLs_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzTn96krTLs_",
        "outputId": "964b6c07-794e-4788-842c-426bfca36e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Sentence Corpus Construction\n",
        "\n",
        "SNIPPETS = [\n",
        "    \"Patches provide steady nicotine during the day. Follow product dosing instructions.\",\n",
        "    \"Chewing gum for nicotine works best with the chew and park technique.\",\n",
        "    \"Set a quit date within two weeks and tell a friend to increase accountability.\",\n",
        "    \"Cravings last a few minutes. Prepare a short list of alternative activities.\"\n",
        "]\n",
        "\n",
        "DEFAULT_URLS = [\n",
        "    \"https://www.webmd.com/smoking-cessation/ss/slideshow-13-best-quit-smoking-tips-ever\",\n",
        "    \"https://www.mayoclinic.org/healthy-lifestyle/quit-smoking/in-depth/nicotine-craving/art-20045454\",\n",
        "    \"https://www.quit.org.au/\"\n",
        "]\n",
        "\n",
        "def build_corpus_sentences(urls: List[str] = None, min_len: int = 30, max_len: int = 400) -> List[str]:\n",
        "    urls = urls or DEFAULT_URLS\n",
        "    text = scrape_articles(urls)\n",
        "    if not text:\n",
        "        # Fallback if scraping is not possible\n",
        "        return SNIPPETS.copy()\n",
        "    sents = sent_tokenize(text)\n",
        "    # Basic filtering and deduplication\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for s in sents:\n",
        "        s_clean = \" \".join(s.split())\n",
        "        if min_len <= len(s_clean) <= max_len and s_clean not in seen:\n",
        "            out.append(s_clean)\n",
        "            seen.add(s_clean)\n",
        "    return out if out else SNIPPETS.copy()\n",
        "\n",
        "corpus_sentences = build_corpus_sentences()\n",
        "len(corpus_sentences)"
      ],
      "id": "GzTn96krTLs_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B93A7Q9dTLs_"
      },
      "source": [
        "## 7. Text Preparation\n",
        "\n",
        "This cell split the combined corpus into sentences and keep a unique list to reduce redundancy. If scraping fails, it fall back to a small internal corpus with practical tips.\n"
      ],
      "id": "B93A7Q9dTLs_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L5vcyKSTLs_",
        "outputId": "c796d9ab-a7be-4f5f-f784-6b0f3ab35bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Use these tips to lessen and resist cravings.',\n",
              " 'These are a better bet for managing strong cravings.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Bag of Words Retrieval\n",
        "\n",
        "def retrieve_from_corpus(query: str, sentences: List[str], top_k: int = 3, min_score: float = 0.05) -> List[str]:\n",
        "    \"\"\"Return up to top_k sentences similar to the query using cosine similarity.\"\"\"\n",
        "    if not sentences:\n",
        "        return []\n",
        "    docs = sentences + [query]\n",
        "    vect = CountVectorizer().fit_transform(docs)\n",
        "    scores = cosine_similarity(vect[-1], vect).flatten()[:-1]  # exclude the query itself\n",
        "    idx = np.argsort(-scores)  # descending\n",
        "    results = []\n",
        "    for i in idx:\n",
        "        if len(results) >= top_k:\n",
        "            break\n",
        "        if scores[i] >= min_score:\n",
        "            results.append(sentences[i])\n",
        "    return results\n",
        "\n",
        "# Quick smoke test\n",
        "retrieve_from_corpus(\"cravings at night\", corpus_sentences, top_k=2)"
      ],
      "id": "7L5vcyKSTLs_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox9nsu4FTLs_"
      },
      "source": [
        "## 8. Retrieval Module (Bag-of-Words Similarity)\n",
        "\n",
        "This cell use a simple bag-of-words model to fetch the top sentences that match the user input. The matching threshold and the number of sentences are configurable.\n"
      ],
      "id": "Ox9nsu4FTLs_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV99rC3KTLtA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Lightweight Generators for Dialogue\n",
        "\n",
        "def greeting_response(text: str):\n",
        "    \"\"\"Return a greeting if the user greets the bot.\"\"\"\n",
        "    text = (text or \"\").lower()\n",
        "    bot_greetings = [\"Hi, how can I help today?\", \"Hello\", \"Hi there\", \"Hey\", \"Hola\", \"Welcome\"]  # English only for consistency\n",
        "    user_greetings = {\"hey\", \"hi\", \"hello\", \"greetings\", \"wassup\", \"halo\"}\n",
        "    for word in text.split():\n",
        "        if word in user_greetings:\n",
        "            return random.choice(bot_greetings)\n",
        "    return None\n",
        "\n",
        "def personalized_motivation(user_data: dict) -> str:\n",
        "    \"\"\"Generate a short motivation message based on user-provided state.\"\"\"\n",
        "    craving_level = int(user_data.get(\"craving_level\", 5))\n",
        "    mood = str(user_data.get(\"mood\", \"\")).lower()\n",
        "    reason_to_quit = user_data.get(\"reason_to_quit\", \"your long-term health\")\n",
        "    messages = []\n",
        "    if craving_level > 7:\n",
        "        messages.append(\"Stay strong. These intense cravings are temporary. Try deep breathing or a short distraction.\")\n",
        "    else:\n",
        "        messages.append(\"You are doing well. Keep a steady pace and acknowledge each small win.\")\n",
        "    if mood in {\"stressed\", \"bored\"}:\n",
        "        messages.append(\"If you feel stressed or bored, try light exercise, reading, or listening to music.\")\n",
        "    messages.append(f\"Remember your main reason: '{reason_to_quit}'. You can reach your goal.\")\n",
        "    return \" \".join(messages)\n",
        "\n",
        "def craving_tips() -> str:\n",
        "    tips = [\n",
        "        \"Drink a glass of water to reduce cravings.\",\n",
        "        \"Take a short walk or do light exercise.\",\n",
        "        \"Practice deep breathing for 5 minutes.\",\n",
        "        \"Use sugar-free gum to keep your mouth busy.\",\n",
        "        \"Recall your reason for quitting to stay focused.\"\n",
        "    ]\n",
        "    return random.choice(tips)"
      ],
      "id": "OV99rC3KTLtA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0co-z2LTLtA"
      },
      "source": [
        "## 9. Generators for Greetings, Motivation, and Craving Tips\n",
        "\n",
        "Small helper functions produce simple, supportive responses. The motivation function uses user-provided metadata that can be collected once per session.\n"
      ],
      "id": "_0co-z2LTLtA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgN5pZYUTLtA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Intent Classifier with TF IDF and Logistic Regression\n",
        "\n",
        "INTENT_LABELS = [\"greet\", \"craving\", \"plan_quit\", \"relapse\", \"info_nrt\", \"goodbye\"]\n",
        "train_texts = [\n",
        "    \"hi there\", \"hello\", \"good morning\",\n",
        "    \"I really want a cigarette right now\", \"cravings are strong today\",\n",
        "    \"I want to set a quit date\", \"help me plan quitting\",\n",
        "    \"I smoked again yesterday\", \"I relapsed after a week\",\n",
        "    \"what is nicotine patch\", \"info about nicotine gum\",\n",
        "    \"thanks bye\", \"goodbye see you\"\n",
        "]\n",
        "train_y = [0,0,0, 1,1, 2,2, 3,3, 4,4, 5,5]\n",
        "\n",
        "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
        "X = tfidf.fit_transform(train_texts)\n",
        "clf = LogisticRegression(max_iter=500, random_state=42)\n",
        "clf.fit(X, train_y)\n",
        "\n",
        "def predict_intent(text: str) -> Tuple[str, float]:\n",
        "    v = tfidf.transform([text])\n",
        "    proba = clf.predict_proba(v)[0]\n",
        "    y = int(proba.argmax())\n",
        "    return INTENT_LABELS[y], float(proba.max())"
      ],
      "id": "KgN5pZYUTLtA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqp_kWZ3TLtA"
      },
      "source": [
        "## 10. Intent Classifier (TF‑IDF + Logistic Regression)\n",
        "\n",
        "A compact supervised classifier routes common intents. The dataset is toy-sized by design so that reviewers can understand each step. It can be replaced with a larger labeled set later.\n"
      ],
      "id": "Zqp_kWZ3TLtA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5gV7xwMTLtA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Dialogue Policy and Session State\n",
        "\n",
        "STAGES = [\"precontemplation\", \"contemplation\", \"preparation\", \"action\", \"maintenance\"]\n",
        "\n",
        "@dataclass\n",
        "class SessionState:\n",
        "    stage: str = \"contemplation\"\n",
        "    last_intent: str = \"\"\n",
        "    relapse_flag: bool = False\n",
        "    history: list = field(default_factory=list)\n",
        "\n",
        "def policy(state: SessionState, user_text: str) -> str:\n",
        "    intent, conf = predict_intent(user_text)\n",
        "    state.last_intent = intent\n",
        "    state.history.append((\"user\", user_text))\n",
        "    if intent == \"plan_quit\":\n",
        "        state.stage = \"preparation\"\n",
        "    elif intent == \"relapse\":\n",
        "        state.relapse_flag = True\n",
        "        state.stage = \"contemplation\"\n",
        "    if intent == \"greet\":\n",
        "        out = \"Hi, I am here to support your quit journey. How are you feeling about smoking today?\"\n",
        "    elif intent == \"craving\":\n",
        "        out = \"Cravings pass. Try a 4D strategy: delay, deep breathing, drink water, do something else.\"\n",
        "    elif intent == \"plan_quit\":\n",
        "        out = \"Good choice. Pick a quit date within two weeks and list your triggers. I can help with the list.\"\n",
        "    elif intent == \"relapse\":\n",
        "        out = \"Slips happen. What did you feel before it happened? We can adjust your plan without judgment.\"\n",
        "    elif intent == \"info_nrt\":\n",
        "        out = \"Nicotine replacement options include patches, gum, lozenges, and sprays.\"\n",
        "    elif intent == \"goodbye\":\n",
        "        out = \"You did well today. I will be here when you need support again.\"\n",
        "    else:\n",
        "        out = \"I want to understand you better. Could you rephrase that?\"\n",
        "    out = apply_safety(user_text, out)\n",
        "    state.history.append((\"bot\", out))\n",
        "    return out"
      ],
      "id": "a5gV7xwMTLtA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5LiXhFQTLtA"
      },
      "source": [
        "## 11. Dialogue Policy and Session State\n",
        "\n",
        "The policy updates a simple stage variable and produces supportive text based on the predicted intent. The safety layer is applied at the end.\n"
      ],
      "id": "J5LiXhFQTLtA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edlEXDzPTLtA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Retrieval Augmentation\n",
        "\n",
        "def retrieve_tips(query: str, k: int = 2):\n",
        "    q = set((query or \"\").lower().split())\n",
        "    scored = []\n",
        "    for s in SNIPPETS:\n",
        "        overlap = len(q & set(s.lower().split()))\n",
        "        scored.append((overlap, s))\n",
        "    scored.sort(key=lambda x: (-x[0], s))\n",
        "    return [s for _, s in scored[:k]]\n",
        "\n",
        "def policy_with_rag(state: SessionState, user_text: str) -> str:\n",
        "    base = policy(state, user_text)\n",
        "    add = retrieve_tips(user_text, k=1)\n",
        "    if add:\n",
        "        base += \" \" + add[0]\n",
        "    return base"
      ],
      "id": "edlEXDzPTLtA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoo-gsWLTLtA"
      },
      "source": [
        "## 12. Retrieval-Augmented Response (RAG-lite)\n",
        "\n",
        "This cell attach one relevant short tip retrieved from a small knowledge list for extra specificity.\n"
      ],
      "id": "xoo-gsWLTLtA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBHXzG_lTLtA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Unified Response Orchestration\n",
        "\n",
        "def generate_response(user_text: str, state: SessionState, corpus_sentences: List[str], user_data: dict) -> str:\n",
        "    # 1) Greetings\n",
        "    g = greeting_response(user_text)\n",
        "    if g:\n",
        "        return apply_safety(user_text, g)\n",
        "\n",
        "    # 2) Keyword shortcuts\n",
        "    low = user_text.lower()\n",
        "    if \"motivation\" in low:\n",
        "        return apply_safety(user_text, personalized_motivation(user_data))\n",
        "    if \"craving\" in low:\n",
        "        return apply_safety(user_text, craving_tips())\n",
        "    if any(k in low for k in [\"exit\", \"bye\", \"quit\"]):\n",
        "        return apply_safety(user_text, \"Thank you for using Qudud. Stay strong and believe in yourself.\")\n",
        "\n",
        "    # 3) Policy response with small RAG tip\n",
        "    out = policy_with_rag(state, user_text)\n",
        "\n",
        "    # 4) If intent confidence is unknown in this simple demo, add corpus sentences\n",
        "    # We approximate low confidence by checking if the policy fell back to the clarification line.\n",
        "    if \"rephrase\" in out.lower():\n",
        "        retrieved = retrieve_from_corpus(user_text, corpus_sentences, top_k=2, min_score=0.05)\n",
        "        if retrieved:\n",
        "            out += \" \" + \" \".join(retrieved)\n",
        "\n",
        "    return apply_safety(user_text, out)"
      ],
      "id": "RBHXzG_lTLtA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FznXTbkoTLtA"
      },
      "source": [
        "## 13. Unified Bot Response\n",
        "\n",
        "This function combines greetings, keyword shortcuts, personalized motivation, and the dialogue policy. The retrieval module adds short relevant sentences from the scraped corpus when confidence is low.\n"
      ],
      "id": "FznXTbkoTLtA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPOK104QTLtA",
        "outputId": "c793069f-8f1a-4fc8-def5-b88fda55544d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Qudud - Interactive Mode\n",
            "Type 'exit' anytime to quit.\n",
            "\n",
            "How many cigarettes do you smoke per day? 7\n",
            "On a scale of 1-10, how strong are your cravings? 9\n",
            "How do you feel right now? I’m really stressed right now\n",
            "What is your main reason for quitting? I want to live a healthy life\n",
            "You: I want to set a quit date\n",
            "Qudud: Thank you for using Qudud. Stay strong and believe in yourself.\n",
            "\n",
            "You: Cravings are strong at night\n",
            "Qudud: Drink a glass of water to reduce cravings.\n",
            "\n",
            "You: What about patches\n",
            "Qudud: Nicotine replacement options include patches, gum, lozenges, and sprays. Patches provide steady nicotine during the day. Follow product dosing instructions.\n",
            "\n",
            "You: Ok thanks\n",
            "Qudud: You did well today. I will be here when you need support again. Patches provide steady nicotine during the day. Follow product dosing instructions.\n",
            "\n",
            "You: Bye\n",
            "Qudud: Thank you for using Qudud. Stay strong and believe in yourself.\n"
          ]
        }
      ],
      "source": [
        "# Interactive Console Demo\n",
        "\n",
        "def run_chat_interactive(max_turns: int | None = None):\n",
        "    \"\"\"\n",
        "    Start an interactive session using input().\n",
        "    Type 'exit', 'quit', or 'bye' to end the session.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        state = SessionState()\n",
        "        print(\"Welcome to Qudud - Interactive Mode\")\n",
        "        print(\"Type 'exit' anytime to quit.\\n\")\n",
        "\n",
        "        # Collect user data once\n",
        "        def _get(prompt, default=\"\"):\n",
        "            try:\n",
        "                v = input(prompt).strip()\n",
        "                return v if v else default\n",
        "            except EOFError:\n",
        "                return default\n",
        "\n",
        "        user_data = {\n",
        "            \"smoking_frequency\": _get(\"How many cigarettes do you smoke per day? \", \"0\"),\n",
        "            \"craving_level\": _get(\"On a scale of 1-10, how strong are your cravings? \", \"5\"),\n",
        "            \"mood\": _get(\"How do you feel right now? \", \"neutral\"),\n",
        "            \"reason_to_quit\": _get(\"What is your main reason for quitting? \", \"health\")\n",
        "        }\n",
        "\n",
        "        turns = 0\n",
        "        while True:\n",
        "            if max_turns is not None and turns >= max_turns:\n",
        "                print(\"Session limit reached.\")\n",
        "                break\n",
        "            try:\n",
        "                u = input(\"You: \").strip()\n",
        "            except EOFError:\n",
        "                print(\"\\nInput stream closed.\")\n",
        "                break\n",
        "            if u.lower() in {\"exit\", \"quit\", \"bye\"}:\n",
        "                print(\"Qudud: Thank you for using Qudud. Stay strong and believe in yourself.\")\n",
        "                break\n",
        "            bot = generate_response(u, state, corpus_sentences, user_data)\n",
        "            print(f\"Qudud: {bot}\\n\")\n",
        "            turns += 1\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nQudud: Goodbye.\")\n",
        "\n",
        "run_chat_interactive()"
      ],
      "id": "GPOK104QTLtA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AFNClseTLtA"
      },
      "source": [
        "## 14. Results\n",
        "\n",
        "This baseline produces clear and supportive messages for each tested intent. It augments low-confidence cases with a short relevant sentence from the corpus to increase specificity. Evaluation for this small demo is qualitative. A next iteration can include human preference judgments and simple satisfaction metrics after each turn.\n"
      ],
      "id": "9AFNClseTLtA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AO6x7GUTLtB"
      },
      "source": [
        "## 15. Insights\n",
        "\n",
        "- Lightweight TF‑IDF with logistic regression is fast and transparent for routing.  \n",
        "- A visible safety check is essential even when simple. It clarifies limits while offering guidance to the user to seek help when needed.  \n",
        "- A minimal retrieval addition increases grounding without complicating the core policy.  \n",
        "- The code organization makes ablations straightforward: disable retrieval, swap the classifier, or extend the safety layer.\n"
      ],
      "id": "3AO6x7GUTLtB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wdRjU9rTLtB"
      },
      "source": [
        "## 16. Responsible Use and Limitations\n",
        "\n",
        "This assistant is not medical advice. It cannot diagnose conditions or handle crises. The safety layer is a simple keyword filter and must be replaced or complemented by a robust classifier in real deployments. Scraping should respect site policies and content licenses.\n"
      ],
      "id": "0wdRjU9rTLtB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFINwNRGTLtB"
      },
      "source": [
        "## 17. Conclusion\n",
        "\n",
        "This notebook illustrates a transparent baseline for a quit-smoking assistant that is easy to read and extend. It is suitable as a reference point for research iterations on intent modeling, retrieval quality, and safety.\n"
      ],
      "id": "KFINwNRGTLtB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kRd7bXrTLtB"
      },
      "source": [
        "## 18. Next Steps\n",
        "\n",
        "- Collect a larger labeled dataset for intents and add per-class metrics.  \n",
        "- Replace bag-of-words retrieval with a compact embedding model that improves semantic matching.  \n",
        "- Add configurable rules for local languages.  \n",
        "- Integrate a better safety classifier and evaluate false negatives.  \n",
        "- Conduct small user studies to measure usefulness and clarity.\n"
      ],
      "id": "4kRd7bXrTLtB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Author / Contact\n",
        "\n",
        "**Rifky Setiawan**  \n",
        "Undergraduate Student, Department of Computer Science  \n",
        "Universitas Gadjah Mada (UGM), Indonesia  \n",
        "Email: rifkysetiawan@mail.ugm.ac.id\n"
      ],
      "metadata": {
        "id": "u6095XfDaPF-"
      },
      "id": "u6095XfDaPF-"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}